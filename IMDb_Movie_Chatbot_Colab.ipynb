{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üé¨ IMDb Movie Chatbot - Enhanced Multi-Agent System\n",
    "\n",
    "## Google Colab Version\n",
    "\n",
    "### Features:\n",
    "- **10+ Specialized AI Agents** for different query types\n",
    "- **Mood-Based Recommendations** - Movies based on how you feel\n",
    "- **Movie Trivia & Facts** - Behind-the-scenes knowledge\n",
    "- **Review/Sentiment Analysis** - Critical reception insights\n",
    "- **Advanced FAISS Vector Search** - Fast, accurate retrieval\n",
    "- **Intelligent Caching** - Faster repeated queries\n",
    "- **Conversation Memory** - Context retention\n",
    "- **Comprehensive Error Handling**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": "# Cell 1: Install Dependencies (Run this first!)\n# This will take 1-2 minutes\n\n# Install required packages (ignore dependency warnings - they don't affect functionality)\n!pip install -q --upgrade langchain langchain-openai langchain-community langchain-text-splitters faiss-cpu gradio python-dotenv openai 2>/dev/null\n\n# Verify installations\nimport importlib\npackages = ['langchain', 'langchain_openai', 'faiss', 'gradio', 'openai']\nall_ok = True\nfor pkg in packages:\n    try:\n        importlib.import_module(pkg.replace('-', '_'))\n    except ImportError:\n        all_ok = False\n        print(f\"‚ùå Failed to import {pkg}\")\n\nif all_ok:\n    print(\"‚úÖ All dependencies installed successfully!\")\nelse:\n    print(\"‚ö†Ô∏è Some packages may need manual installation\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Mount Google Drive & Set Dataset Path\n",
    "# Upload your IMDb_Dataset.csv to Google Drive first\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# UPDATE THIS PATH to match your Google Drive location\n",
    "DATASET_PATH = '/content/drive/MyDrive/IMDb_Dataset (1).csv'\n",
    "\n",
    "# Alternative: Upload directly to Colab (uncomment below)\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# DATASET_PATH = list(uploaded.keys())[0]\n",
    "\n",
    "print(f\"Dataset path set to: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "api_key"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Set OpenAI API Key\n",
    "\n",
    "import os\n",
    "\n",
    "# Option A: Try to get from Colab Secrets first\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"‚úÖ API key loaded from Colab Secrets\")\n",
    "except:\n",
    "    OPENAI_API_KEY = None\n",
    "\n",
    "# Option B: If not in secrets, prompt for input\n",
    "if not OPENAI_API_KEY:\n",
    "    from getpass import getpass\n",
    "    OPENAI_API_KEY = getpass(\"Enter your OpenAI API key: \")\n",
    "    print(\"‚úÖ API key entered manually\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "print(\"‚úÖ OpenAI API key configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Import All Libraries\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import Tuple, List, Dict, Optional, Any, Set\n",
    "import time\n",
    "import random\n",
    "import hashlib\n",
    "import re\n",
    "from collections import deque, OrderedDict\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# Gradio for UI\n",
    "import gradio as gr\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Logging setup\n",
    "LOG_DIR = \"logs\"\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "log_filename = os.path.join(LOG_DIR, f\"chatbot_{datetime.now().strftime('%Y%m%d')}.log\")\n",
    "\n",
    "logger = logging.getLogger(\"MovieChatbot\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Load and Explore Dataset\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded: {df.shape[0]} movies, {df.shape[1]} features\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"   Year Range: {df['Year'].min()} - {df['Year'].max()}\")\n",
    "print(f\"   Rating Range: {df['IMDb Rating'].min()} - {df['IMDb Rating'].max()}\")\n",
    "print(f\"   Unique Directors: {df['Director'].nunique()}\")\n",
    "print(f\"   Unique Genres: {df['Genre'].nunique()}\")\n",
    "\n",
    "# Display sample\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_descriptions"
   },
   "outputs": [],
   "source": [
    "# Cell 6: Create Movie Descriptions\n",
    "\n",
    "def create_movie_description(row):\n",
    "    \"\"\"Create a rich text description for each movie.\"\"\"\n",
    "    title = row['Title'] if pd.notna(row['Title']) else 'Unknown Title'\n",
    "    year = int(row['Year']) if pd.notna(row['Year']) else 'Unknown Year'\n",
    "    genre = row['Genre'] if pd.notna(row['Genre']) else 'Unknown Genre'\n",
    "    director = row['Director'] if pd.notna(row['Director']) else 'Unknown Director'\n",
    "    cast = row['Star Cast'] if pd.notna(row['Star Cast']) else 'Unknown Cast'\n",
    "    rating = row['IMDb Rating'] if pd.notna(row['IMDb Rating']) else 'N/A'\n",
    "    metascore = row['MetaScore'] if pd.notna(row['MetaScore']) else 'N/A'\n",
    "    certificate = row['Certificates'] if pd.notna(row['Certificates']) else 'Not Rated'\n",
    "    duration = int(row['Duration (minutes)']) if pd.notna(row['Duration (minutes)']) else 'Unknown'\n",
    "    poster = row['Poster-src'] if pd.notna(row['Poster-src']) else ''\n",
    "\n",
    "    description = f\"\"\"Movie Title: {title}\n",
    "Year: {year}\n",
    "Genre: {genre}\n",
    "Director: {director}\n",
    "Star Cast: {cast}\n",
    "IMDb Rating: {rating}/10\n",
    "MetaScore: {metascore}\n",
    "Certificate: {certificate}\n",
    "Duration: {duration} minutes\n",
    "Poster URL: {poster}\n",
    "\n",
    "This is a {genre} movie titled \"{title}\" released in {year}, directed by {director} and starring {cast}. It has an IMDb rating of {rating}/10 and MetaScore of {metascore}. The film runs for {duration} minutes.\"\"\"\n",
    "\n",
    "    return description\n",
    "\n",
    "print(\"Creating movie descriptions...\")\n",
    "df['description'] = df.apply(create_movie_description, axis=1)\n",
    "\n",
    "print(f\"\\n‚úÖ Created descriptions for {len(df)} movies\")\n",
    "print(f\"\\nSample description:\")\n",
    "print(\"-\" * 50)\n",
    "print(df['description'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_documents"
   },
   "outputs": [],
   "source": [
    "# Cell 7: Create Documents and Embeddings\n",
    "\n",
    "def create_documents_from_dataframe(df):\n",
    "    \"\"\"Convert DataFrame rows to LangChain Document objects.\"\"\"\n",
    "    documents = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        metadata = {\n",
    "            'title': row['Title'] if pd.notna(row['Title']) else 'Unknown',\n",
    "            'year': int(row['Year']) if pd.notna(row['Year']) else 0,\n",
    "            'genre': row['Genre'] if pd.notna(row['Genre']) else 'Unknown',\n",
    "            'director': row['Director'] if pd.notna(row['Director']) else 'Unknown',\n",
    "            'rating': float(row['IMDb Rating']) if pd.notna(row['IMDb Rating']) else 0.0,\n",
    "            'metascore': float(row['MetaScore']) if pd.notna(row['MetaScore']) else 0.0,\n",
    "            'certificate': row['Certificates'] if pd.notna(row['Certificates']) else 'Not Rated',\n",
    "            'poster_url': row['Poster-src'] if pd.notna(row['Poster-src']) else '',\n",
    "            'duration': int(row['Duration (minutes)']) if pd.notna(row['Duration (minutes)']) else 0,\n",
    "            'cast': row['Star Cast'] if pd.notna(row['Star Cast']) else 'Unknown',\n",
    "        }\n",
    "\n",
    "        doc = Document(page_content=row['description'], metadata=metadata)\n",
    "        documents.append(doc)\n",
    "\n",
    "    return documents\n",
    "\n",
    "print(\"Converting to documents...\")\n",
    "documents = create_documents_from_dataframe(df)\n",
    "print(f\"\\n‚úÖ Created {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_vectorstore"
   },
   "outputs": [],
   "source": [
    "# Cell 8: Create FAISS Vector Store\n",
    "\n",
    "print(\"Initializing embeddings model...\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "print(\"Creating FAISS vector store...\")\n",
    "vectorstore = FAISS.from_documents(documents=documents, embedding=embeddings)\n",
    "\n",
    "print(f\"\\n‚úÖ Vector store created with {vectorstore.index.ntotal} vectors\")\n",
    "\n",
    "# Test similarity search\n",
    "print(\"\\nTesting similarity search...\")\n",
    "test_results = vectorstore.similarity_search(\"comedy movie\", k=3)\n",
    "for i, doc in enumerate(test_results, 1):\n",
    "    print(f\"{i}. {doc.metadata['title']} ({doc.metadata['year']}) - {doc.metadata['rating']}/10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "initialize_llm"
   },
   "outputs": [],
   "source": [
    "# Cell 9: Initialize LLM\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1200,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM initialized\")\n",
    "print(\"   Model: gpt-4o-mini\")\n",
    "print(\"   Temperature: 0.7\")\n",
    "\n",
    "# Test LLM\n",
    "test_response = llm.invoke(\"Say 'Hello, movie fan!' in one sentence.\")\n",
    "print(f\"\\nü§ñ LLM Test: {test_response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "# Cell 10: Configuration & Constants\n",
    "\n",
    "# Cache configuration\n",
    "CACHE_MAX_SIZE = 100\n",
    "CACHE_TTL_SECONDS = 3600  # 1 hour\n",
    "SEMANTIC_SIMILARITY_THRESHOLD = 0.92\n",
    "\n",
    "# Rate limiting\n",
    "RATE_LIMIT_REQUESTS = 30\n",
    "RATE_LIMIT_WINDOW = 60  # seconds\n",
    "\n",
    "# Mood to Genre Mapping for Mood-Based Recommendations\n",
    "MOOD_GENRE_MAPPING = {\n",
    "    \"happy\": [\"Comedy\", \"Animation\", \"Musical\", \"Family\"],\n",
    "    \"sad\": [\"Drama\", \"Romance\"],\n",
    "    \"excited\": [\"Action\", \"Adventure\", \"Sci-Fi\", \"Thriller\"],\n",
    "    \"scared\": [\"Horror\", \"Mystery\", \"Thriller\"],\n",
    "    \"romantic\": [\"Romance\", \"Drama\", \"Comedy\"],\n",
    "    \"thoughtful\": [\"Documentary\", \"Biography\", \"Drama\", \"History\"],\n",
    "    \"nostalgic\": [\"Classic\", \"Family\", \"Animation\"],\n",
    "    \"adventurous\": [\"Adventure\", \"Action\", \"Fantasy\", \"Sci-Fi\"],\n",
    "    \"relaxed\": [\"Comedy\", \"Animation\", \"Family\", \"Documentary\"],\n",
    "    \"inspired\": [\"Biography\", \"Documentary\", \"Drama\", \"Sport\"]\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"   Cache Size: {CACHE_MAX_SIZE}\")\n",
    "print(f\"   Rate Limit: {RATE_LIMIT_REQUESTS} requests per {RATE_LIMIT_WINDOW}s\")\n",
    "print(f\"   Mood Categories: {len(MOOD_GENRE_MAPPING)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caching_system"
   },
   "outputs": [],
   "source": [
    "# Cell 11: Caching and Rate Limiting\n",
    "\n",
    "class QueryCache:\n",
    "    \"\"\"Dual-layer caching with exact match and semantic similarity.\"\"\"\n",
    "\n",
    "    def __init__(self, max_size: int = CACHE_MAX_SIZE, ttl: int = CACHE_TTL_SECONDS):\n",
    "        self.max_size = max_size\n",
    "        self.ttl = ttl\n",
    "        self.exact_cache: OrderedDict = OrderedDict()\n",
    "        self.stats = {\"exact_hits\": 0, \"misses\": 0}\n",
    "\n",
    "    def _hash_query(self, query: str) -> str:\n",
    "        return hashlib.md5(query.lower().strip().encode()).hexdigest()\n",
    "\n",
    "    def get(self, query: str) -> Optional[Dict]:\n",
    "        query_hash = self._hash_query(query)\n",
    "        if query_hash in self.exact_cache:\n",
    "            entry = self.exact_cache[query_hash]\n",
    "            if time.time() - entry['timestamp'] < self.ttl:\n",
    "                self.stats[\"exact_hits\"] += 1\n",
    "                return entry['response']\n",
    "            del self.exact_cache[query_hash]\n",
    "        self.stats[\"misses\"] += 1\n",
    "        return None\n",
    "\n",
    "    def set(self, query: str, response: Dict):\n",
    "        while len(self.exact_cache) >= self.max_size:\n",
    "            self.exact_cache.popitem(last=False)\n",
    "        query_hash = self._hash_query(query)\n",
    "        self.exact_cache[query_hash] = {'response': response, 'timestamp': time.time()}\n",
    "\n",
    "    def get_stats(self) -> Dict:\n",
    "        total = sum(self.stats.values())\n",
    "        hit_rate = (self.stats[\"exact_hits\"] / total * 100) if total > 0 else 0\n",
    "        return {**self.stats, \"hit_rate_percent\": round(hit_rate, 2)}\n",
    "\n",
    "\n",
    "class RateLimiter:\n",
    "    \"\"\"Sliding window rate limiter.\"\"\"\n",
    "\n",
    "    def __init__(self, max_requests: int = RATE_LIMIT_REQUESTS, window_seconds: int = RATE_LIMIT_WINDOW):\n",
    "        self.max_requests = max_requests\n",
    "        self.window_seconds = window_seconds\n",
    "        self.requests: deque = deque()\n",
    "\n",
    "    def is_allowed(self) -> Tuple[bool, int]:\n",
    "        now = time.time()\n",
    "        while self.requests and now - self.requests[0] > self.window_seconds:\n",
    "            self.requests.popleft()\n",
    "        if len(self.requests) < self.max_requests:\n",
    "            self.requests.append(now)\n",
    "            return True, 0\n",
    "        wait_time = int(self.window_seconds - (now - self.requests[0])) + 1\n",
    "        return False, wait_time\n",
    "\n",
    "\n",
    "class ConversationMemory:\n",
    "    \"\"\"Conversation memory with context retention.\"\"\"\n",
    "\n",
    "    def __init__(self, max_turns: int = 10):\n",
    "        self.max_turns = max_turns\n",
    "        self.history: List[Dict] = []\n",
    "        self.context_entities: Set[str] = set()\n",
    "\n",
    "    def add_turn(self, user_query: str, assistant_response: str, metadata: Dict = None):\n",
    "        self.history.append({\n",
    "            \"user\": user_query,\n",
    "            \"assistant\": assistant_response,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"metadata\": metadata or {}\n",
    "        })\n",
    "        if len(self.history) > self.max_turns:\n",
    "            self.history.pop(0)\n",
    "        if metadata and \"posters\" in metadata:\n",
    "            for p in metadata[\"posters\"]:\n",
    "                if p.get(\"title\"):\n",
    "                    self.context_entities.add(p[\"title\"])\n",
    "\n",
    "    def get_context_summary(self) -> str:\n",
    "        if not self.history:\n",
    "            return \"\"\n",
    "        recent = self.history[-3:]\n",
    "        summary = \"Recent conversation:\\n\"\n",
    "        for turn in recent:\n",
    "            summary += f\"User: {turn['user'][:80]}...\\n\"\n",
    "            summary += f\"Assistant: {turn['assistant'][:100]}...\\n\\n\"\n",
    "        if self.context_entities:\n",
    "            summary += f\"Previously discussed: {', '.join(list(self.context_entities)[:5])}\"\n",
    "        return summary\n",
    "\n",
    "    def clear(self):\n",
    "        self.history = []\n",
    "        self.context_entities = set()\n",
    "\n",
    "print(\"‚úÖ Caching and memory systems defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "query_classifier"
   },
   "outputs": [],
   "source": [
    "# Cell 12: Enhanced Query Classifier\n",
    "\n",
    "class EnhancedQueryClassifier:\n",
    "    \"\"\"Advanced query classifier with pattern matching.\"\"\"\n",
    "\n",
    "    QUERY_PATTERNS = {\n",
    "        \"genre_search\": {\n",
    "            \"keywords\": [\"genre\", \"comedy\", \"action\", \"drama\", \"horror\", \"thriller\", \"romance\",\n",
    "                        \"documentary\", \"biography\", \"adventure\", \"sci-fi\", \"animation\", \"fantasy\",\n",
    "                        \"mystery\", \"crime\", \"war\", \"western\", \"musical\", \"sport\", \"family\"],\n",
    "            \"patterns\": [r\"(find|show|get|list).*(comedy|action|drama|horror)\", r\"\\b(genres?)\\b\"]\n",
    "        },\n",
    "        \"actor_search\": {\n",
    "            \"keywords\": [\"actor\", \"actress\", \"starring\", \"star\", \"played by\", \"cast\", \"featuring\"],\n",
    "            \"patterns\": [r\"movies?\\s+(with|starring|featuring)\\s+\", r\"(actor|actress)\\s+\\w+\"]\n",
    "        },\n",
    "        \"director_search\": {\n",
    "            \"keywords\": [\"director\", \"directed\", \"filmmaker\", \"made by\"],\n",
    "            \"patterns\": [r\"(directed|director)\\s+by?\\s*\\w+\", r\"films?\\s+by\\s+\"]\n",
    "        },\n",
    "        \"rating_search\": {\n",
    "            \"keywords\": [\"rating\", \"rated\", \"best\", \"top\", \"highest\", \"score\", \"imdb\"],\n",
    "            \"patterns\": [r\"(top|best|highest)\\s+\\d*\\s*(rated|movies?)\"]\n",
    "        },\n",
    "        \"year_search\": {\n",
    "            \"keywords\": [\"year\", \"released\", \"from 19\", \"from 20\", \"decade\", \"era\"],\n",
    "            \"patterns\": [r\"(in|from|since)\\s*(19|20)\\d{2}\", r\"(decade|era|years?)\"]\n",
    "        },\n",
    "        \"comparison\": {\n",
    "            \"keywords\": [\"compare\", \"versus\", \"vs\", \"difference\", \"better\"],\n",
    "            \"patterns\": [r\"(compare|versus|vs\\.?)\\s+\"]\n",
    "        },\n",
    "        \"recommendation\": {\n",
    "            \"keywords\": [\"recommend\", \"suggest\", \"similar\", \"like\", \"should i watch\"],\n",
    "            \"patterns\": [r\"(recommend|suggest)\\s+(me\\s+)?\", r\"similar\\s+to\\s+\"]\n",
    "        },\n",
    "        \"mood_based\": {\n",
    "            \"keywords\": [\"mood\", \"feeling\", \"feel like\", \"happy\", \"sad\", \"excited\", \"scared\",\n",
    "                        \"romantic\", \"thoughtful\", \"nostalgic\", \"adventurous\", \"relaxed\", \"inspired\"],\n",
    "            \"patterns\": [r\"(mood|feeling|feel\\s+like)\", r\"i('m|\\s+am)\\s+(happy|sad|excited|scared)\"]\n",
    "        },\n",
    "        \"trivia\": {\n",
    "            \"keywords\": [\"trivia\", \"fact\", \"facts\", \"interesting\", \"did you know\", \"fun fact\"],\n",
    "            \"patterns\": [r\"(trivia|facts?)\\s+(about|for)\"]\n",
    "        },\n",
    "        \"review_sentiment\": {\n",
    "            \"keywords\": [\"review\", \"reviews\", \"critics\", \"audience\", \"reception\"],\n",
    "            \"patterns\": [r\"(reviews?|critics?|reception)\"]\n",
    "        },\n",
    "        \"duration_search\": {\n",
    "            \"keywords\": [\"duration\", \"runtime\", \"long\", \"short\", \"minutes\", \"length\"],\n",
    "            \"patterns\": [r\"(duration|runtime|length)\", r\"(short|long)\\s+movies?\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def classify(self, query: str) -> Tuple[str, float]:\n",
    "        query_lower = query.lower()\n",
    "        scores = {}\n",
    "\n",
    "        for query_type, config in self.QUERY_PATTERNS.items():\n",
    "            score = 0\n",
    "            for keyword in config[\"keywords\"]:\n",
    "                if keyword in query_lower:\n",
    "                    score += 1\n",
    "            for pattern in config[\"patterns\"]:\n",
    "                if re.search(pattern, query_lower):\n",
    "                    score += 2\n",
    "            if score > 0:\n",
    "                scores[query_type] = score\n",
    "\n",
    "        if not scores:\n",
    "            return \"general_search\", 0.5\n",
    "\n",
    "        best_type = max(scores, key=scores.get)\n",
    "        confidence = min(scores[best_type] / 5.0, 1.0)\n",
    "        return best_type, confidence\n",
    "\n",
    "\n",
    "# Test classifier\n",
    "classifier = EnhancedQueryClassifier()\n",
    "test_queries = [\n",
    "    \"Recommend comedy movies\",\n",
    "    \"Movies with Tom Hanks\",\n",
    "    \"I'm feeling sad, what should I watch?\",\n",
    "    \"Trivia about Inception\",\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Query Classifier Tests:\")\n",
    "for q in test_queries:\n",
    "    qtype, conf = classifier.classify(q)\n",
    "    print(f\"   '{q}' -> {qtype} ({conf:.0%} confidence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "base_agent"
   },
   "outputs": [],
   "source": [
    "# Cell 13: Base Agent Class\n",
    "\n",
    "class BaseAgent(ABC):\n",
    "    \"\"\"Abstract base class for all specialized agents.\"\"\"\n",
    "\n",
    "    def __init__(self, name: str, description: str, llm, vectorstore, df):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.llm = llm\n",
    "        self.vectorstore = vectorstore\n",
    "        self.df = df\n",
    "        self.retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "    def get_context(self, query: str, k: int = 5) -> List[Document]:\n",
    "        self.retriever.search_kwargs[\"k\"] = k\n",
    "        return self.retriever.invoke(query)\n",
    "\n",
    "    def format_context(self, docs: List[Document]) -> str:\n",
    "        return \"\\n\\n---\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    def extract_posters(self, docs: List[Document], limit: int = 5) -> List[Dict]:\n",
    "        posters = []\n",
    "        for doc in docs:\n",
    "            if doc.metadata.get('poster_url'):\n",
    "                posters.append(doc.metadata)\n",
    "        return posters[:limit]\n",
    "\n",
    "    @abstractmethod\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        pass\n",
    "\n",
    "    def _create_response(self, answer: str, docs: List[Document], extra_data: Dict = None) -> Dict[str, Any]:\n",
    "        response = {\n",
    "            \"answer\": answer,\n",
    "            \"posters\": self.extract_posters(docs),\n",
    "            \"agent\": self.name,\n",
    "            \"description\": self.description\n",
    "        }\n",
    "        if extra_data:\n",
    "            response.update(extra_data)\n",
    "        return response\n",
    "\n",
    "print(\"‚úÖ BaseAgent class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "specialized_agents"
   },
   "outputs": [],
   "source": [
    "# Cell 14: Specialized Agents (10+ Agents)\n",
    "\n",
    "class GenreRecommendationAgent(BaseAgent):\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        super().__init__(\"Genre Expert\", \"Genre-based movie recommendations\", llm, vectorstore, df)\n",
    "\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        docs = self.get_context(query, k=8)\n",
    "        prompt = f\"\"\"You are an expert movie curator specializing in film genres.\n",
    "CONTEXT: {context}\\nMOVIE DATABASE:\\n{self.format_context(docs)}\\n\\nUSER QUERY: {query}\\n\\n\n",
    "Provide 3-5 genre-specific recommendations with Title, Year, Rating, and why it's great.\"\"\"\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        return self._create_response(response.content, docs)\n",
    "\n",
    "\n",
    "class ActorDirectorAgent(BaseAgent):\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        super().__init__(\"Filmography Expert\", \"Actor and director career analysis\", llm, vectorstore, df)\n",
    "\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        docs = self.get_context(query, k=10)\n",
    "        prompt = f\"\"\"You are a film industry expert with deep knowledge of actors' and directors' careers.\n",
    "CONTEXT: {context}\\nFILMOGRAPHY DATABASE:\\n{self.format_context(docs)}\\n\\nUSER QUERY: {query}\\n\\n\n",
    "List notable films with Title, Year, Genre, Rating, and career highlights.\"\"\"\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        return self._create_response(response.content, docs)\n",
    "\n",
    "\n",
    "class RatingFilterAgent(BaseAgent):\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        super().__init__(\"Rating Analyst\", \"IMDb ratings and critical reception expert\", llm, vectorstore, df)\n",
    "\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        high_rated = self.df[self.df['IMDb Rating'] >= 8.0].nlargest(15, 'IMDb Rating')\n",
    "        docs = self.get_context(query, k=8)\n",
    "        top_movies = \"\\n\".join([f\"- {row['Title']} ({row['Year']}) - IMDb: {row['IMDb Rating']}/10\" for _, row in high_rated.head(10).iterrows()])\n",
    "        prompt = f\"\"\"You are a film critic expert.\\nTOP RATED:\\n{top_movies}\\n\\nCONTEXT: {self.format_context(docs)}\\n\\nQUERY: {query}\\n\\nRecommend highly-rated movies.\"\"\"\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        return self._create_response(response.content, docs)\n",
    "\n",
    "\n",
    "class MovieComparisonAgent(BaseAgent):\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        super().__init__(\"Comparison Analyst\", \"Movie comparison expert\", llm, vectorstore, df)\n",
    "\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        docs = self.get_context(query, k=8)\n",
    "        prompt = f\"\"\"You are a film analyst expert at comparisons.\\nCONTEXT: {context}\\n\\nMOVIE DATABASE:\\n{self.format_context(docs)}\\n\\nQUERY: {query}\\n\\nCreate a structured comparison.\"\"\"\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        return self._create_response(response.content, docs)\n",
    "\n",
    "\n",
    "class MoodBasedAgent(BaseAgent):\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        super().__init__(\"Mood Curator\", \"Mood-based movie recommendations\", llm, vectorstore, df)\n",
    "\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        query_lower = query.lower()\n",
    "        detected_mood = \"relaxed\"\n",
    "        for mood in MOOD_GENRE_MAPPING.keys():\n",
    "            if mood in query_lower:\n",
    "                detected_mood = mood\n",
    "                break\n",
    "        mood_genres = MOOD_GENRE_MAPPING.get(detected_mood, [\"Drama\"])\n",
    "        genre_pattern = '|'.join(mood_genres)\n",
    "        mood_movies = self.df[self.df['Genre'].str.contains(genre_pattern, case=False, na=False)]\n",
    "        top_mood = mood_movies.nlargest(10, 'IMDb Rating')\n",
    "        mood_list = \"\\n\".join([f\"- {row['Title']} ({row['Year']}) - {row['Genre']} - {row['IMDb Rating']}/10\" for _, row in top_mood.head(8).iterrows()])\n",
    "        docs = self.get_context(f\"{detected_mood} {' '.join(mood_genres)}\", k=8)\n",
    "        prompt = f\"\"\"You are an empathetic movie curator.\\n\\nDETECTED MOOD: {detected_mood.upper()}\\nRECOMMENDED GENRES: {', '.join(mood_genres)}\\n\\nMOOD-MATCHED MOVIES:\\n{mood_list}\\n\\nQUERY: {query}\\n\\nRecommend 4-5 movies that match their mood. Be warm and understanding!\"\"\"\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        return self._create_response(response.content, docs, {\"detected_mood\": detected_mood})\n",
    "\n",
    "\n",
    "class TriviaAgent(BaseAgent):\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        super().__init__(\"Trivia Master\", \"Movie trivia and behind-the-scenes facts\", llm, vectorstore, df)\n",
    "\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        docs = self.get_context(query, k=6)\n",
    "        prompt = f\"\"\"You are an entertaining movie trivia expert.\\n\\nCONTEXT: {context}\\nMOVIE DATABASE:\\n{self.format_context(docs)}\\n\\nQUERY: {query}\\n\\nShare 5-7 fascinating trivia facts. Use \"Did you know...\" and \"Fun fact:\" language!\"\"\"\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        return self._create_response(response.content, docs)\n",
    "\n",
    "\n",
    "class ReviewSentimentAgent(BaseAgent):\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        super().__init__(\"Review Analyst\", \"Critical and audience reception analysis\", llm, vectorstore, df)\n",
    "\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        docs = self.get_context(query, k=6)\n",
    "        movie_ratings = [f\"{d.metadata.get('title', 'Unknown')}: IMDb {d.metadata.get('rating', 0)}/10, MetaScore {d.metadata.get('metascore', 0)}\" for d in docs[:3]]\n",
    "        prompt = f\"\"\"You are a film critic who synthesizes reception.\\n\\nRATINGS:\\n{chr(10).join(movie_ratings)}\\n\\nDETAILS:\\n{self.format_context(docs)}\\n\\nQUERY: {query}\\n\\nAnalyze critical reception, audience response, and give a verdict.\"\"\"\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        return self._create_response(response.content, docs)\n",
    "\n",
    "\n",
    "class SimilarMoviesAgent(BaseAgent):\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        super().__init__(\"Similarity Finder\", \"Finds movies similar to ones you love\", llm, vectorstore, df)\n",
    "\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        docs = self.get_context(query, k=12)\n",
    "        prompt = f\"\"\"You are a movie recommendation expert.\\nCONTEXT: {context}\\n\\nSIMILAR MOVIES:\\n{self.format_context(docs)}\\n\\nQUERY: {query}\\n\\nRecommend 5-6 similar movies. Explain the CONNECTION.\"\"\"\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        return self._create_response(response.content, docs)\n",
    "\n",
    "\n",
    "class DurationAgent(BaseAgent):\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        super().__init__(\"Runtime Advisor\", \"Finds movies based on available time\", llm, vectorstore, df)\n",
    "\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        query_lower = query.lower()\n",
    "        if any(word in query_lower for word in [\"short\", \"quick\", \"brief\"]):\n",
    "            duration_filter = self.df[self.df['Duration (minutes)'] <= 100]\n",
    "            duration_desc = \"short (under 100 minutes)\"\n",
    "        elif any(word in query_lower for word in [\"long\", \"epic\", \"extended\"]):\n",
    "            duration_filter = self.df[self.df['Duration (minutes)'] >= 150]\n",
    "            duration_desc = \"epic length (150+ minutes)\"\n",
    "        else:\n",
    "            duration_filter = self.df[(self.df['Duration (minutes)'] >= 90) & (self.df['Duration (minutes)'] <= 130)]\n",
    "            duration_desc = \"standard length (90-130 minutes)\"\n",
    "        top_duration = duration_filter.nlargest(10, 'IMDb Rating')\n",
    "        docs = self.get_context(query, k=6)\n",
    "        duration_list = \"\\n\".join([f\"- {row['Title']} ({row['Year']}) - {row['Duration (minutes)']} min - {row['IMDb Rating']}/10\" for _, row in top_duration.head(8).iterrows()])\n",
    "        prompt = f\"\"\"You are a movie guide for time-conscious viewers.\\n\\nDURATION: {duration_desc}\\n\\nMATCHING MOVIES:\\n{duration_list}\\n\\nQUERY: {query}\\n\\nRecommend movies with exact runtime.\"\"\"\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        return self._create_response(response.content, docs)\n",
    "\n",
    "\n",
    "class YearEraAgent(BaseAgent):\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        super().__init__(\"Era Explorer\", \"Cinema history across decades\", llm, vectorstore, df)\n",
    "\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        year_match = re.search(r'(19|20)\\d{2}', query)\n",
    "        decade_match = re.search(r'(19|20)\\d{1}0s', query)\n",
    "        if decade_match:\n",
    "            decade_start = int(decade_match.group()[:4])\n",
    "            era_filter = self.df[(self.df['Year'] >= decade_start) & (self.df['Year'] < decade_start + 10)]\n",
    "            era_desc = f\"the {decade_match.group()}\"\n",
    "        elif year_match:\n",
    "            year = int(year_match.group())\n",
    "            era_filter = self.df[(self.df['Year'] >= year - 2) & (self.df['Year'] <= year + 2)]\n",
    "            era_desc = f\"around {year}\"\n",
    "        else:\n",
    "            era_filter = self.df[self.df['Year'] >= 2020]\n",
    "            era_desc = \"recent years (2020+)\"\n",
    "        top_era = era_filter.nlargest(10, 'IMDb Rating')\n",
    "        docs = self.get_context(query, k=8)\n",
    "        era_list = \"\\n\".join([f\"- {row['Title']} ({row['Year']}) - {row['Genre']} - {row['IMDb Rating']}/10\" for _, row in top_era.head(8).iterrows()])\n",
    "        prompt = f\"\"\"You are a cinema historian.\\n\\nERA: {era_desc}\\n\\nTOP MOVIES:\\n{era_list}\\n\\nQUERY: {query}\\n\\nRecommend the best from this era.\"\"\"\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        return self._create_response(response.content, docs)\n",
    "\n",
    "\n",
    "class GeneralSearchAgent(BaseAgent):\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        super().__init__(\"General Assistant\", \"Versatile movie knowledge assistant\", llm, vectorstore, df)\n",
    "\n",
    "    def invoke(self, query: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        docs = self.get_context(query, k=8)\n",
    "        prompt = f\"\"\"You are a knowledgeable movie assistant.\\nCONTEXT: {context}\\n\\nMOVIE DATABASE:\\n{self.format_context(docs)}\\n\\nQUERY: {query}\\n\\nProvide helpful, engaging recommendations.\"\"\"\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        return self._create_response(response.content, docs)\n",
    "\n",
    "\n",
    "print(\"‚úÖ 11 Specialized Agents defined:\")\n",
    "agents_list = [\"Genre Expert\", \"Filmography Expert\", \"Rating Analyst\", \"Comparison Analyst\",\n",
    "               \"Mood Curator\", \"Trivia Master\", \"Review Analyst\", \"Similarity Finder\",\n",
    "               \"Runtime Advisor\", \"Era Explorer\", \"General Assistant\"]\n",
    "for i, agent in enumerate(agents_list, 1):\n",
    "    print(f\"   {i}. {agent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orchestrator"
   },
   "outputs": [],
   "source": [
    "# Cell 15: Multi-Agent Orchestrator\n",
    "\n",
    "class MultiAgentOrchestrator:\n",
    "    \"\"\"Orchestrates multiple specialized agents with intelligent routing.\"\"\"\n",
    "\n",
    "    def __init__(self, llm, vectorstore, df):\n",
    "        self.classifier = EnhancedQueryClassifier()\n",
    "        self.memory = ConversationMemory()\n",
    "        self.cache = QueryCache()\n",
    "        self.rate_limiter = RateLimiter()\n",
    "\n",
    "        # Initialize all agents\n",
    "        self.agents = {\n",
    "            \"genre_search\": GenreRecommendationAgent(llm, vectorstore, df),\n",
    "            \"actor_search\": ActorDirectorAgent(llm, vectorstore, df),\n",
    "            \"director_search\": ActorDirectorAgent(llm, vectorstore, df),\n",
    "            \"rating_search\": RatingFilterAgent(llm, vectorstore, df),\n",
    "            \"year_search\": YearEraAgent(llm, vectorstore, df),\n",
    "            \"comparison\": MovieComparisonAgent(llm, vectorstore, df),\n",
    "            \"recommendation\": SimilarMoviesAgent(llm, vectorstore, df),\n",
    "            \"mood_based\": MoodBasedAgent(llm, vectorstore, df),\n",
    "            \"trivia\": TriviaAgent(llm, vectorstore, df),\n",
    "            \"review_sentiment\": ReviewSentimentAgent(llm, vectorstore, df),\n",
    "            \"duration_search\": DurationAgent(llm, vectorstore, df),\n",
    "            \"general_search\": GeneralSearchAgent(llm, vectorstore, df),\n",
    "        }\n",
    "        self.query_history = []\n",
    "        self.agent_usage = {}\n",
    "\n",
    "    def process(self, query: str) -> Dict[str, Any]:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Input validation\n",
    "        validation = self._validate_input(query)\n",
    "        if not validation[\"valid\"]:\n",
    "            return {\"answer\": validation[\"message\"], \"posters\": [], \"agent\": \"Input Validator\"}\n",
    "\n",
    "        # Rate limiting\n",
    "        allowed, wait_time = self.rate_limiter.is_allowed()\n",
    "        if not allowed:\n",
    "            return {\"answer\": f\"Too many requests. Please wait {wait_time} seconds.\", \"posters\": [], \"agent\": \"Rate Limiter\"}\n",
    "\n",
    "        # Check cache\n",
    "        cached = self.cache.get(query)\n",
    "        if cached:\n",
    "            cached[\"from_cache\"] = True\n",
    "            return cached\n",
    "\n",
    "        # Classify and route\n",
    "        query_type, confidence = self.classifier.classify(query)\n",
    "        agent = self.agents.get(query_type, self.agents[\"general_search\"])\n",
    "\n",
    "        # Get conversation context\n",
    "        context = self.memory.get_context_summary()\n",
    "\n",
    "        # Process\n",
    "        try:\n",
    "            result = agent.invoke(query, context)\n",
    "            result[\"query_type\"] = query_type\n",
    "            result[\"confidence\"] = confidence\n",
    "            result[\"processing_time\"] = round(time.time() - start_time, 2)\n",
    "            result[\"from_cache\"] = False\n",
    "\n",
    "            self.memory.add_turn(query, result[\"answer\"], {\"posters\": result.get(\"posters\", [])})\n",
    "            self._update_stats(agent.name, query_type)\n",
    "            self.cache.set(query, result)\n",
    "\n",
    "            logger.info(f\"Query: type={query_type}, agent={agent.name}, time={result['processing_time']}s\")\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error: {str(e)}\")\n",
    "            return {\"answer\": f\"Error processing request: {str(e)}\", \"posters\": [], \"agent\": \"Error Handler\"}\n",
    "\n",
    "    def _validate_input(self, query: str) -> Dict:\n",
    "        if not query:\n",
    "            return {\"valid\": False, \"message\": \"Please enter a question about movies.\"}\n",
    "        query = query.strip()\n",
    "        if len(query) < 3:\n",
    "            return {\"valid\": False, \"message\": \"Question too short. Please provide more details.\"}\n",
    "        if len(query) > 1000:\n",
    "            return {\"valid\": False, \"message\": \"Question too long. Please keep it under 1000 characters.\"}\n",
    "        harmful = [r'<script', r'javascript:', r'DROP TABLE', r'DELETE FROM']\n",
    "        for pattern in harmful:\n",
    "            if re.search(pattern, query, re.IGNORECASE):\n",
    "                return {\"valid\": False, \"message\": \"Invalid input.\"}\n",
    "        return {\"valid\": True, \"message\": \"\"}\n",
    "\n",
    "    def _update_stats(self, agent_name: str, query_type: str):\n",
    "        self.agent_usage[agent_name] = self.agent_usage.get(agent_name, 0) + 1\n",
    "        self.query_history.append({\"timestamp\": datetime.now().isoformat(), \"query_type\": query_type, \"agent\": agent_name})\n",
    "\n",
    "    def get_stats(self) -> Dict:\n",
    "        return {\"total_queries\": len(self.query_history), \"agent_usage\": self.agent_usage, \"cache_stats\": self.cache.get_stats(), \"agents_available\": len(self.agents)}\n",
    "\n",
    "    def clear_history(self):\n",
    "        self.memory.clear()\n",
    "\n",
    "\n",
    "# Initialize the orchestrator\n",
    "print(\"üöÄ Initializing Multi-Agent Orchestrator...\")\n",
    "orchestrator = MultiAgentOrchestrator(llm, vectorstore, df)\n",
    "print(f\"‚úÖ Multi-Agent System Ready with {len(orchestrator.agents)} agents!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_system"
   },
   "outputs": [],
   "source": "# Cell 16: Comprehensive Test Suite with Edge Cases\n\nTEST_CASES = {\n    \"Basic Functionality\": [\n        (\"BF001\", \"Genre Search\", \"Recommend some comedy movies\"),\n        (\"BF002\", \"Actor Search\", \"Movies with Tom Hanks\"),\n        (\"BF003\", \"Director Search\", \"Films by Christopher Nolan\"),\n        (\"BF004\", \"Rating Filter\", \"Top rated movies above 8.5\"),\n        (\"BF005\", \"Year Search\", \"Best movies from 2020\"),\n    ],\n    \"Advanced Agents\": [\n        (\"AA001\", \"Mood Based\", \"I'm feeling happy, what should I watch?\"),\n        (\"AA002\", \"Mood Sad\", \"I'm feeling sad today\"),\n        (\"AA003\", \"Trivia\", \"Trivia about The Dark Knight\"),\n        (\"AA004\", \"Review\", \"Reviews for Inception\"),\n        (\"AA005\", \"Similar\", \"Movies similar to Interstellar\"),\n        (\"AA006\", \"Duration Short\", \"Short movies under 100 minutes\"),\n        (\"AA007\", \"Duration Long\", \"Epic long movies over 3 hours\"),\n        (\"AA008\", \"Era 90s\", \"Best movies from the 1990s\"),\n        (\"AA009\", \"Comparison\", \"Compare Inception and Interstellar\"),\n    ],\n    \"Edge Cases - Input Validation\": [\n        (\"EC001\", \"Empty Input\", \"\"),\n        (\"EC002\", \"Too Short\", \"hi\"),\n        (\"EC003\", \"Single Character\", \"a\"),\n        (\"EC004\", \"Only Spaces\", \"   \"),\n        (\"EC005\", \"Very Long Input\", \"movie \" * 200),\n    ],\n    \"Edge Cases - Unusual Queries\": [\n        (\"EC006\", \"Non-movie Query\", \"What's the weather today?\"),\n        (\"EC007\", \"Numbers Only\", \"12345\"),\n        (\"EC008\", \"Special Characters\", \"!@#$%^&*()\"),\n        (\"EC009\", \"Mixed Language\", \"Find me peliculas de accion\"),\n        (\"EC010\", \"Typos\", \"Recomend comdy moveis\"),\n    ],\n    \"Edge Cases - Security\": [\n        (\"EC011\", \"SQL Injection\", \"'; DROP TABLE movies; --\"),\n        (\"EC012\", \"Script Injection\", \"<script>alert('xss')</script>\"),\n        (\"EC013\", \"Command Injection\", \"movie; rm -rf /\"),\n    ],\n    \"Edge Cases - Ambiguous Queries\": [\n        (\"EC014\", \"Vague Query\", \"good movie\"),\n        (\"EC015\", \"Multiple Intents\", \"comedy movies with action and romance from 90s\"),\n        (\"EC016\", \"Contradictory\", \"short movies that are very long\"),\n    ],\n    \"Cache & Performance\": [\n        (\"CP001\", \"Repeated Query 1\", \"Recommend comedy movies\"),\n        (\"CP002\", \"Repeated Query 2\", \"Recommend comedy movies\"),  # Should hit cache\n        (\"CP003\", \"Similar Query\", \"Suggest comedy films\"),  # Test semantic similarity\n    ],\n}\n\n\ndef run_comprehensive_tests():\n    \"\"\"Run all test cases and report results.\"\"\"\n    print(\"=\" * 70)\n    print(\"üß™ MULTI-AGENT SYSTEM - COMPREHENSIVE TEST SUITE\")\n    print(\"=\" * 70)\n    \n    results = {\"passed\": 0, \"failed\": 0, \"errors\": 0}\n    detailed_results = []\n    \n    for category, tests in TEST_CASES.items():\n        print(f\"\\nüìã {category}\")\n        print(\"-\" * 50)\n        \n        for test_id, test_name, query in tests:\n            try:\n                start_time = time.time()\n                result = orchestrator.process(query)\n                elapsed = round(time.time() - start_time, 2)\n                \n                # Determine expected behavior and check\n                if test_id in [\"EC001\", \"EC004\"]:  # Empty/spaces\n                    success = \"please\" in result['answer'].lower() or \"enter\" in result['answer'].lower()\n                elif test_id in [\"EC002\", \"EC003\"]:  # Too short\n                    success = \"short\" in result['answer'].lower() or \"details\" in result['answer'].lower()\n                elif test_id == \"EC005\":  # Too long\n                    success = \"long\" in result['answer'].lower() or \"1000\" in result['answer'].lower()\n                elif test_id in [\"EC011\", \"EC012\", \"EC013\"]:  # Security\n                    success = \"invalid\" in result['answer'].lower() or len(result['answer']) > 20\n                elif test_id == \"CP002\":  # Cache hit\n                    success = result.get('from_cache', False) == True\n                else:  # Normal queries\n                    success = len(result['answer']) > 50 and result.get('agent') != \"Error Handler\"\n                \n                status = \"‚úÖ PASS\" if success else \"‚ùå FAIL\"\n                results[\"passed\" if success else \"failed\"] += 1\n                \n                # Detailed output\n                cache_info = \"‚ö°cached\" if result.get('from_cache') else f\"{elapsed}s\"\n                print(f\"  [{test_id}] {test_name}: {status}\")\n                print(f\"           Agent: {result['agent']} | {cache_info}\")\n                \n                if not success:\n                    print(f\"           Response: {result['answer'][:80]}...\")\n                \n                detailed_results.append({\n                    \"id\": test_id, \"name\": test_name, \"status\": \"PASS\" if success else \"FAIL\",\n                    \"agent\": result['agent'], \"time\": elapsed, \"cached\": result.get('from_cache', False)\n                })\n                \n            except Exception as e:\n                results[\"errors\"] += 1\n                print(f\"  [{test_id}] {test_name}: ‚ö†Ô∏è ERROR\")\n                print(f\"           {str(e)[:60]}\")\n                detailed_results.append({\"id\": test_id, \"name\": test_name, \"status\": \"ERROR\", \"error\": str(e)})\n    \n    # Summary\n    total = sum(results.values())\n    pass_rate = (results[\"passed\"] / total * 100) if total > 0 else 0\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"üìä TEST RESULTS SUMMARY\")\n    print(\"=\" * 70)\n    print(f\"  ‚úÖ Passed:  {results['passed']}/{total}\")\n    print(f\"  ‚ùå Failed:  {results['failed']}/{total}\")\n    print(f\"  ‚ö†Ô∏è Errors:  {results['errors']}/{total}\")\n    print(f\"  üìà Pass Rate: {pass_rate:.1f}%\")\n    \n    # Cache stats\n    cache_stats = orchestrator.cache.get_stats()\n    print(f\"\\n  üì¶ Cache Performance:\")\n    print(f\"     - Exact Hits: {cache_stats['exact_hits']}\")\n    print(f\"     - Misses: {cache_stats['misses']}\")\n    print(f\"     - Hit Rate: {cache_stats['hit_rate_percent']}%\")\n    \n    # Agent usage\n    print(f\"\\n  ü§ñ Agent Usage:\")\n    for agent, count in sorted(orchestrator.agent_usage.items(), key=lambda x: x[1], reverse=True):\n        print(f\"     - {agent}: {count} queries\")\n    \n    print(\"=\" * 70)\n    \n    return results, detailed_results\n\n\n# Run the comprehensive test suite\nprint(\"üöÄ Starting Comprehensive Test Suite...\\n\")\ntest_results, detailed = run_comprehensive_tests()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gradio_ui"
   },
   "outputs": [],
   "source": "# Cell 17: Gradio Chat Interface\n\ndef chat_with_agents(message: str, history: list) -> str:\n    \"\"\"Main chat function.\"\"\"\n    result = orchestrator.process(message)\n\n    agent_info = f\"**ü§ñ {result['agent']}**\"\n    cache_info = \" ‚ö°(cached)\" if result.get('from_cache') else \"\"\n    time_info = f\" | {result.get('processing_time', 'N/A')}s\" if not result.get('from_cache') else \"\"\n\n    response = f\"{agent_info}{cache_info}{time_info}\\n\\n{result['answer']}\"\n    return response\n\n\n# Create Gradio Interface (compatible with latest Gradio version)\ndemo = gr.ChatInterface(\n    fn=chat_with_agents,\n    title=\"üé¨ IMDb Movie Chatbot - Enhanced Multi-Agent System\",\n    description=\"\"\"Powered by **10+ Specialized AI Agents**:\n    Genre Expert | Filmography Expert | Rating Analyst | Mood Curator | Trivia Master | Review Analyst | Similarity Finder | Runtime Advisor | Era Explorer\n\n    **Try asking:**\n    - \"Recommend comedy movies\" | \"Movies with Leonardo DiCaprio\"\n    - \"I'm feeling sad, what should I watch?\" | \"Trivia about Inception\"\n    - \"Top rated documentaries\" | \"Short movies under 100 minutes\"\n    - \"Compare Inception and Interstellar\" | \"Best movies from the 1990s\"\n    \"\"\",\n    examples=[\n        \"Recommend comedy movies\",\n        \"Movies with Leonardo DiCaprio\",\n        \"I'm feeling happy, what should I watch?\",\n        \"Trivia about The Dark Knight\",\n        \"Top rated documentaries\",\n        \"Compare Inception and Interstellar\",\n        \"Short movies under 100 minutes\",\n        \"Best movies from the 1990s\",\n        \"Movies similar to The Shawshank Redemption\",\n        \"Reviews for Pulp Fiction\"\n    ]\n)\n\nprint(\"‚úÖ Gradio UI Created!\")\nprint(\"\\nüöÄ Launching... (check the output below for the public URL)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch"
   },
   "outputs": [],
   "source": [
    "# Cell 18: Launch the Chatbot!\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "Your Enhanced Multi-Agent IMDb Movie Chatbot is now running!\n",
    "\n",
    "### ü§ñ Available Agents:\n",
    "| Agent | Description | Example Query |\n",
    "|-------|-------------|---------------|\n",
    "| **Genre Expert** | Genre-based recommendations | \"Recommend comedy movies\" |\n",
    "| **Filmography Expert** | Actor/director careers | \"Movies with Tom Hanks\" |\n",
    "| **Rating Analyst** | Rating-based searches | \"Top rated documentaries\" |\n",
    "| **Mood Curator** | Mood-based picks | \"I'm feeling sad\" |\n",
    "| **Trivia Master** | Fun facts | \"Trivia about Inception\" |\n",
    "| **Review Analyst** | Critical reception | \"Reviews for Pulp Fiction\" |\n",
    "| **Similarity Finder** | Similar movies | \"Movies like The Matrix\" |\n",
    "| **Runtime Advisor** | Duration-based | \"Short movies\" |\n",
    "| **Era Explorer** | Decade/year search | \"Best of the 90s\" |\n",
    "| **Comparison Analyst** | Movie comparisons | \"Compare action vs thriller\" |\n",
    "| **General Assistant** | Versatile queries | \"Tell me about Inception\" |\n",
    "\n",
    "---\n",
    "\n",
    "*Built with LangChain, FAISS, OpenAI GPT-4o-mini, and Gradio*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}