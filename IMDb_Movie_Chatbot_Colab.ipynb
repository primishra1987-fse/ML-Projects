{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¬ IMDb Movie Chatbot - Google Colab Version\n",
    "\n",
    "This notebook implements an AI-powered movie recommendation chatbot using:\n",
    "- **RAG (Retrieval-Augmented Generation)** for accurate movie information\n",
    "- **FAISS Vector Search** for fast similarity matching\n",
    "- **OpenAI GPT** for natural language understanding\n",
    "- **Agentic AI Architecture** with specialized movie tools\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Instructions\n",
    "1. Run Cell 1 to install dependencies\n",
    "2. Run Cell 2 to mount Google Drive (upload your dataset there)\n",
    "3. Run Cell 3 to set your OpenAI API key\n",
    "4. Run all remaining cells in order\n",
    "5. Launch the Gradio UI in the final cell\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install Dependencies (Run this first!)\n",
    "# This will take 1-2 minutes\n",
    "\n",
    "!pip install -q langchain langchain-openai langchain-community faiss-cpu gradio python-dotenv openai\n",
    "\n",
    "print(\"âœ… All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Mount Google Drive & Set Dataset Path\n",
    "# Upload your IMDb_Dataset.csv to Google Drive first\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# UPDATE THIS PATH to match your Google Drive location\n",
    "# Example: '/content/drive/MyDrive/IMDb_Dataset.csv'\n",
    "DATASET_PATH = '/content/drive/MyDrive/IMDb_Dataset (1).csv'\n",
    "\n",
    "# Alternative: Upload directly to Colab (uncomment below)\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()  # This will prompt you to upload\n",
    "# DATASET_PATH = list(uploaded.keys())[0]\n",
    "\n",
    "print(f\"Dataset path set to: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Set OpenAI API Key\n",
    "# Option A: Use Colab Secrets (Recommended)\n",
    "# Option B: Enter directly (less secure)\n",
    "\n",
    "import os\n",
    "\n",
    "# Option A: Try to get from Colab Secrets first\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"âœ… API key loaded from Colab Secrets\")\n",
    "except:\n",
    "    OPENAI_API_KEY = None\n",
    "\n",
    "# Option B: If not in secrets, prompt for input\n",
    "if not OPENAI_API_KEY:\n",
    "    from getpass import getpass\n",
    "    OPENAI_API_KEY = getpass(\"Enter your OpenAI API key: \")\n",
    "    print(\"âœ… API key entered manually\")\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "print(\"âœ… OpenAI API key configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Import Libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Gradio for UI\n",
    "import gradio as gr\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Load the Dataset\n",
    "\n",
    "# Load the IMDb dataset\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "print(f\"âœ… Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape[0]} movies, {df.shape[1]} features\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "\n",
    "# Show sample\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Exploratory Data Analysis\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Data types and non-null counts\n",
    "print(\"\\nðŸ“‹ Data Types & Missing Values:\")\n",
    "print(df.info())\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nðŸ“ˆ Statistical Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nâš ï¸ Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing Count': missing, 'Percentage': missing_pct})\n",
    "display(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Key stats\n",
    "print(f\"\\nðŸŽ­ Unique Values:\")\n",
    "print(f\"- Genres: {df['Genre'].nunique()} unique\")\n",
    "print(f\"- Directors: {df['Director'].nunique()} unique\")\n",
    "print(f\"- Year range: {df['Year'].min()} - {df['Year'].max()}\")\n",
    "print(f\"- Rating range: {df['IMDb Rating'].min()} - {df['IMDb Rating'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create Movie Descriptions\n",
    "\n",
    "def create_movie_description(row):\n",
    "    \"\"\"Create a rich text description for each movie.\"\"\"\n",
    "    title = row['Title'] if pd.notna(row['Title']) else 'Unknown Title'\n",
    "    year = int(row['Year']) if pd.notna(row['Year']) else 'Unknown Year'\n",
    "    genre = row['Genre'] if pd.notna(row['Genre']) else 'Unknown Genre'\n",
    "    director = row['Director'] if pd.notna(row['Director']) else 'Unknown Director'\n",
    "    cast = row['Star Cast'] if pd.notna(row['Star Cast']) else 'Unknown Cast'\n",
    "    rating = row['IMDb Rating'] if pd.notna(row['IMDb Rating']) else 'N/A'\n",
    "    metascore = row['MetaScore'] if pd.notna(row['MetaScore']) else 'N/A'\n",
    "    certificate = row['Certificates'] if pd.notna(row['Certificates']) else 'Not Rated'\n",
    "    duration = int(row['Duration (minutes)']) if pd.notna(row['Duration (minutes)']) else 'Unknown'\n",
    "    poster = row['Poster-src'] if pd.notna(row['Poster-src']) else ''\n",
    "    \n",
    "    description = f\"\"\"\n",
    "Movie Title: {title}\n",
    "Year: {year}\n",
    "Genre: {genre}\n",
    "Director: {director}\n",
    "Star Cast: {cast}\n",
    "IMDb Rating: {rating}/10\n",
    "MetaScore: {metascore}\n",
    "Certificate: {certificate}\n",
    "Duration: {duration} minutes\n",
    "\n",
    "This is a {genre} movie titled \"{title}\" released in {year}. \n",
    "It was directed by {director} and stars {cast}. \n",
    "The film has an IMDb rating of {rating}/10 and a MetaScore of {metascore}.\n",
    "\"\"\".strip()\n",
    "    \n",
    "    return description\n",
    "\n",
    "print(\"Creating movie descriptions...\")\n",
    "df['description'] = df.apply(create_movie_description, axis=1)\n",
    "\n",
    "print(f\"\\nâœ… Created descriptions for {len(df)} movies\")\n",
    "print(f\"\\nSample description:\")\n",
    "print(\"-\" * 50)\n",
    "print(df['description'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Create Documents for Vector Store\n",
    "\n",
    "def create_documents_from_dataframe(df):\n",
    "    \"\"\"Convert DataFrame rows to LangChain Document objects.\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        metadata = {\n",
    "            'title': row['Title'] if pd.notna(row['Title']) else 'Unknown',\n",
    "            'year': int(row['Year']) if pd.notna(row['Year']) else 0,\n",
    "            'genre': row['Genre'] if pd.notna(row['Genre']) else 'Unknown',\n",
    "            'director': row['Director'] if pd.notna(row['Director']) else 'Unknown',\n",
    "            'rating': float(row['IMDb Rating']) if pd.notna(row['IMDb Rating']) else 0.0,\n",
    "            'certificate': row['Certificates'] if pd.notna(row['Certificates']) else 'Not Rated',\n",
    "            'poster_url': row['Poster-src'] if pd.notna(row['Poster-src']) else '',\n",
    "            'index': idx\n",
    "        }\n",
    "        \n",
    "        doc = Document(page_content=row['description'], metadata=metadata)\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "print(\"Converting to documents...\")\n",
    "documents = create_documents_from_dataframe(df)\n",
    "print(f\"\\nâœ… Created {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Create Embeddings Model\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "print(\"âœ… OpenAI Embeddings initialized\")\n",
    "print(\"   Model: text-embedding-3-small\")\n",
    "\n",
    "# Quick test\n",
    "test_embed = embeddings.embed_query(\"action movie\")\n",
    "print(f\"   Embedding dimensions: {len(test_embed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Create FAISS Vector Store\n",
    "# This cell may take 2-5 minutes for ~3000 movies\n",
    "\n",
    "print(\"Creating FAISS vector store...\")\n",
    "print(f\"Processing {len(documents)} documents (this may take a few minutes)...\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Vector store created with {vectorstore.index.ntotal} vectors\")\n",
    "\n",
    "# Test search\n",
    "print(\"\\nðŸ” Testing search...\")\n",
    "test_results = vectorstore.similarity_search(\"comedy movie\", k=3)\n",
    "for i, doc in enumerate(test_results, 1):\n",
    "    print(f\"   {i}. {doc.metadata['title']} ({doc.metadata['year']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Create LLM and RAG Chain\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "print(\"âœ… LLM initialized (gpt-4o-mini)\")\n",
    "\n",
    "# Create prompt template\n",
    "MOVIE_PROMPT = \"\"\"You are an expert Movie Recommendation Assistant with access to the IMDb database.\n",
    "\n",
    "Use the following movie information to answer the user's question:\n",
    "\n",
    "{context}\n",
    "\n",
    "Guidelines:\n",
    "1. Only recommend movies from the provided context\n",
    "2. Provide details like title, year, genre, director, cast, and ratings\n",
    "3. Be conversational and helpful\n",
    "4. If no relevant movies found, say so politely\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=MOVIE_PROMPT, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# Create chains\n",
    "combine_docs_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "retrieval_chain = create_retrieval_chain(retriever=retriever, combine_docs_chain=combine_docs_chain)\n",
    "\n",
    "print(\"âœ… RAG chain assembled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Test the RAG Chain\n",
    "\n",
    "def ask_movie_bot(question: str) -> dict:\n",
    "    \"\"\"Process a question through the RAG chain.\"\"\"\n",
    "    return retrieval_chain.invoke({\"input\": question})\n",
    "\n",
    "# Test\n",
    "print(\"ðŸŽ¬ Testing Movie Chatbot\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_q = \"Recommend some good documentary movies\"\n",
    "print(f\"\\nðŸ“ Query: {test_q}\")\n",
    "response = ask_movie_bot(test_q)\n",
    "print(f\"\\nðŸ¤– Response:\\n{response['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Create Agent Tools\n",
    "\n",
    "@tool\n",
    "def search_movies_by_query(query: str) -> str:\n",
    "    \"\"\"Search for movies based on a natural language query.\"\"\"\n",
    "    response = retrieval_chain.invoke({\"input\": query})\n",
    "    return response['answer']\n",
    "\n",
    "@tool\n",
    "def get_movie_details(movie_title: str) -> str:\n",
    "    \"\"\"Get detailed information about a specific movie by title.\"\"\"\n",
    "    query = f\"Tell me everything about the movie titled {movie_title}\"\n",
    "    response = retrieval_chain.invoke({\"input\": query})\n",
    "    return response['answer']\n",
    "\n",
    "@tool\n",
    "def recommend_movies_by_genre(genre: str) -> str:\n",
    "    \"\"\"Recommend movies from a specific genre.\"\"\"\n",
    "    query = f\"Recommend the best {genre} movies with high ratings\"\n",
    "    response = retrieval_chain.invoke({\"input\": query})\n",
    "    return response['answer']\n",
    "\n",
    "@tool\n",
    "def find_movies_by_actor(actor_name: str) -> str:\n",
    "    \"\"\"Find movies featuring a specific actor.\"\"\"\n",
    "    query = f\"Find movies starring {actor_name}\"\n",
    "    response = retrieval_chain.invoke({\"input\": query})\n",
    "    return response['answer']\n",
    "\n",
    "@tool\n",
    "def find_movies_by_director(director_name: str) -> str:\n",
    "    \"\"\"Find movies by a specific director.\"\"\"\n",
    "    query = f\"Find movies directed by {director_name}\"\n",
    "    response = retrieval_chain.invoke({\"input\": query})\n",
    "    return response['answer']\n",
    "\n",
    "tools = [\n",
    "    search_movies_by_query,\n",
    "    get_movie_details,\n",
    "    recommend_movies_by_genre,\n",
    "    find_movies_by_actor,\n",
    "    find_movies_by_director,\n",
    "]\n",
    "\n",
    "print(f\"âœ… Created {len(tools)} agent tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Create Agent Orchestrator\n",
    "\n",
    "AGENT_PROMPT = \"\"\"You are a helpful Movie Recommendation Assistant powered by the IMDb database.\n",
    "You have tools to search movies, get details, recommend by genre, and find by actor/director.\n",
    "Always be helpful and provide detailed movie information.\"\"\"\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", AGENT_PROMPT),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=agent_prompt)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=5,\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent Orchestrator created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Create Chatbot Class with Error Handling\n",
    "\n",
    "class MovieChatbot:\n",
    "    def __init__(self, agent_executor):\n",
    "        self.agent = agent_executor\n",
    "        self.history = []\n",
    "        \n",
    "    def chat(self, user_input: str) -> str:\n",
    "        if not user_input or len(user_input.strip()) < 3:\n",
    "            return \"âš ï¸ Please enter a more detailed question about movies.\"\n",
    "        \n",
    "        if len(user_input) > 1000:\n",
    "            return \"âš ï¸ Your question is too long. Please keep it under 1000 characters.\"\n",
    "        \n",
    "        try:\n",
    "            response = self.agent.invoke({\"input\": user_input})\n",
    "            self.history.append({\"user\": user_input, \"assistant\": response['output']})\n",
    "            return response['output']\n",
    "        except Exception as e:\n",
    "            return f\"âš ï¸ An error occurred: {str(e)}\"\n",
    "    \n",
    "    def clear_history(self):\n",
    "        self.history = []\n",
    "        self.agent.memory.clear()\n",
    "        return \"History cleared!\"\n",
    "\n",
    "chatbot = MovieChatbot(agent_executor)\n",
    "print(\"âœ… Chatbot ready!\")\n",
    "\n",
    "# Test\n",
    "print(\"\\nðŸ§ª Test: \")\n",
    "print(chatbot.chat(\"Recommend a documentary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Launch Gradio Interface\n",
    "# Run this cell to start the chatbot UI!\n",
    "\n",
    "def chat_fn(message: str, history: list) -> str:\n",
    "    return chatbot.chat(message)\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_fn,\n",
    "    title=\"ðŸŽ¬ IMDb Movie Chatbot\",\n",
    "    description=\"Ask me anything about movies! I can recommend films, find movies by genre, director, or actors.\",\n",
    "    examples=[\n",
    "        \"Recommend some highly rated documentaries\",\n",
    "        \"Find movies starring Tom Hanks\",\n",
    "        \"What are some good adventure movies?\",\n",
    "        \"Tell me about biography films\",\n",
    "    ],\n",
    "    theme=\"soft\"\n",
    ")\n",
    "\n",
    "# Launch with public URL for sharing\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "Your IMDb Movie Chatbot is now running!\n",
    "\n",
    "### Features:\n",
    "- **RAG-powered** responses using your IMDb dataset\n",
    "- **Agentic AI** with specialized movie tools\n",
    "- **Conversation memory** for context-aware responses\n",
    "- **Error handling** for robust operation\n",
    "\n",
    "### Try asking:\n",
    "- \"Recommend a good documentary\"\n",
    "- \"Find movies by Christopher Nolan\"\n",
    "- \"What are the highest rated films?\"\n",
    "- \"Movies starring Robert De Niro\"\n",
    "\n",
    "---\n",
    "\n",
    "*Built with LangChain, FAISS, OpenAI, and Gradio*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
